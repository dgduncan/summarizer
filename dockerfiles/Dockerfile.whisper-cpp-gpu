# Use NVIDIA CUDA base image to support GPU
FROM nvidia/cuda:13.1.0-devel-ubuntu24.04

# Install system dependencies (Python, FFmpeg, Git)
RUN apt-get update && apt-get install -y \
    # python3.10 \
    # python3-pip \
    # python3-dev \
    git \
    wget2 \
    cmake \
    # ffmpeg \
    nvidia-cuda-dev \
    && rm -rf /var/lib/apt/lists/*

# Set the working directory inside the container
WORKDIR /app

# Shallow clone whisper.cpp repository
RUN git clone https://github.com/ggml-org/whisper.cpp.git --depth 1
WORKDIR /app/whisper.cpp

# Download models to run
RUN sh ./models/download-ggml-model.sh tiny.en

# Build for CUDA support
RUN cmake -B build -DGGML_CUDA=1 -DCMAKE_CUDA_ARCHITECTURES="86"
RUN cmake --build build -j --config Release

# # Set environment variables
# ENV PYTHONUNBUFFERED=1
# ENV DEBIAN_FRONTEND=noninteractive

# # Install system dependencies (Python, FFmpeg, Git)
# RUN apt-get update && apt-get install -y \
#     python3.10 \
#     python3-pip \
#     python3-dev \
#     git \
#     ffmpeg \
#     && rm -rf /var/lib/apt/lists/*

# # Alias python3 to python
# RUN ln -s /usr/bin/python3 /usr/bin/python

# # Upgrade pip
# RUN pip install --no-cache-dir --upgrade pip

# # Install PyTorch with CUDA 11.8 support explicitly first
# RUN pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118

# # Copy requirements and install
# COPY requirements.txt .
# RUN pip install --no-cache-dir -r requirements.txt

# # Copy application code
# COPY main.py .

# # Expose the port
# EXPOSE 8080

# # Run the application
# CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8080"]